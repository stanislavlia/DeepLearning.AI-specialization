{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c8bd740",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12be9fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression():\n",
    "    def __init__(self):\n",
    "        \n",
    "        #initializing empty variables\n",
    "        self.X_train = None\n",
    "        self.y_train = None\n",
    "        \n",
    "        self.alpha = None\n",
    "        self.W = None\n",
    "        self.b = None\n",
    "        \n",
    "        self.n_features = None\n",
    "        self.m = None #num of examples in train set\n",
    "        self.epochs = None\n",
    "        \n",
    "    def set_model(self, X_train, y_train, alpha=0.1, epochs=100):\n",
    "        #assigning variables\n",
    "        \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.alpha = alpha\n",
    "        self.epochs = epochs\n",
    "        \n",
    "        self.m = X_train.shape[0]\n",
    "        self.n_features = X_train.shape[1]\n",
    "        \n",
    "        #initialize params\n",
    "        self.W = np.zeros((self.n_features, 1))\n",
    "        self.b = 0\n",
    "        \n",
    "    def _sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        predictions = np.dot(X, self.W) + b\n",
    "        transformed_preds = self._sigmoid(predictions)\n",
    "        \n",
    "        return transformed_preds\n",
    "    \n",
    "    \n",
    "    def _cost(self, predictions):\n",
    "        \n",
    "        return   (-1 / self.m)* np.sum( y_train * np.log(predictions) + (1 - y_train) * np.log(1 - predictions)) \n",
    "        \n",
    "        \n",
    "    def fit(self):\n",
    "        \n",
    "        history = []\n",
    "        \n",
    "        for i in range(self.epochs):\n",
    "            \n",
    "            predictions = self.predict(X_train)\n",
    "            \n",
    "            \n",
    "            cost = self._cost(predictions)\n",
    "            print(\"i = {}; BinaryCrossEntropy = {}\".format(i, cost))\n",
    "            history.append(cost)\n",
    "            \n",
    "            errors = (predictions - self.y_train)\n",
    "            \n",
    "            gradients_W =  np.dot(self.X_train.T, errors) / self.m\n",
    "            gradient_b =   np.sum(errors) / self.m\n",
    "            \n",
    "            #correcting weights\n",
    "            self.W = self.W - alpha * gradients_W\n",
    "            self.b = self.b - alpha * gradient_b\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1350b58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.86405365],\n",
       "       [1.5166767 ],\n",
       "       [1.41222341],\n",
       "       [1.71331134],\n",
       "       [1.40882631]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af0c8b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
